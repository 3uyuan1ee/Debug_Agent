name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # 每天凌晨2点运行
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'

jobs:
  # 代码质量检查
  code-quality:
    name: Code Quality Check
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Lint with flake8
      run: |
        pip install flake8
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Type check with mypy
      run: |
        pip install mypy
        mypy src/ --ignore-missing-imports || true

    - name: Security check with bandit
      run: |
        pip install bandit
        bandit -r src/ -f json -o bandit-report.json || true

    - name: Upload security report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-report
        path: bandit-report.json

  # 单元测试
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run tests
      run: |
        python -m pytest tests/ -v --cov=src/ --cov-report=xml --cov-report=html

    - name: Upload coverage reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: coverage-reports
        path: |
          coverage.xml
          htmlcov/

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Agent功能测试
  agent-tests:
    name: Agent Functionality Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Agent tests
      run: |
        python -m pytest tests/agents/ -v --tb=short
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: Test Agent workflow
      run: |
        python -c "
        import sys
        sys.path.append('src')
        from agents.debug_agent import DebugAgent
        print('Agent initialization test passed')
        "
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

  # 集成测试
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run integration tests
      run: |
        python -m pytest tests/integration/ -v --tb=short
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

  # 性能测试
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark

    - name: Run performance tests
      run: |
        python -m pytest tests/performance/ -v --benchmark-only
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: Generate performance report
      run: |
        python scripts/generate_performance_report.py || true

  # 构建和打包
  build:
    name: Build and Package
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Build package
      run: |
        python -m build

    - name: Check package
      run: |
        python -m twine check dist/*

    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: python-package
        path: dist/

  # 文档构建
  documentation:
    name: Build Documentation
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocs-mermaid2-plugin

    - name: Build documentation
      run: |
        mkdocs build || true

    - name: Upload documentation
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: documentation
        path: site/

  # 部署到开发环境
  deploy-dev:
    name: Deploy to Development
    runs-on: ubuntu-latest
    needs: [build, agent-tests]
    if: github.ref == 'refs/heads/develop'
    environment: development

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: python-package
        path: dist/

    - name: Deploy to development
      run: |
        echo "Deploying to development environment..."
        # 这里可以添加实际的部署脚本
        echo "Development deployment completed"

  # 部署到生产环境
  deploy-prod:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build, agent-tests, performance-tests]
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: python-package
        path: dist/

    - name: Deploy to production
      run: |
        echo "Deploying to production environment..."
        # 这里可以添加实际的生产部署脚本
        echo "Production deployment completed"

  # 生成报告
  generate-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, agent-tests, performance-tests]
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v3

    - name: Generate comprehensive report
      run: |
        echo "Generating comprehensive test report..."
        mkdir -p reports

        # 创建测试总结报告
        cat > reports/test-summary.md << EOF
        # CI/CD Test Summary

        ## Test Results

        ### Unit Tests: ${{ needs.unit-tests.result }}
        ### Integration Tests: ${{ needs.integration-tests.result }}
        ### Agent Tests: ${{ needs.agent-tests.result }}
        ### Performance Tests: ${{ needs.performance-tests.result }}

        ## Build Information

        - **Commit**: ${{ github.sha }}
        - **Branch**: ${{ github.ref_name }}
        - **Run ID**: ${{ github.run_id }}
        - **Run Number**: ${{ github.run_number }}

        ## Artifacts Generated

        - Coverage reports
        - Security scan results
        - Performance benchmarks
        - Python package

        Generated on: $(date)
        EOF

    - name: Upload test report
      uses: actions/upload-artifact@v3
      with:
        name: test-reports
        path: reports/

  # 通知
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [generate-report]
    if: always()

    steps:
    - name: Send notification
      run: |
        echo "CI/CD pipeline completed with status: ${{ job.status }}"
        echo "View results at: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"